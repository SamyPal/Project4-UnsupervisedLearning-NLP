{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as request\n",
    "from urllib.error import HTTPError\n",
    "from datetime import datetime\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "DESCRIPTIVE_KEYS = {\n",
    "    'id': 'ID',\n",
    "    't': 'TickerSymbol',\n",
    "    'e': 'Exchange',\n",
    "    'l': 'LastTradePrice',\n",
    "    'lt_dts': 'LastTradeDateTime',\n",
    "    'c': 'Change',\n",
    "    'cp': 'ChangePercent',\n",
    "    'pcls_fix': 'PreviousCloseFix',\n",
    "    'div': 'Dividend',\n",
    "    'yld': 'Dividend Yield'\n",
    "}\n",
    "\n",
    "class Stock:\n",
    "\n",
    "    \"\"\"Class contains functions to pull current and historical pricing data from\n",
    "        Google Finance\n",
    "    Functions\n",
    "    ---------\n",
    "        get_quote: returns the most recent market quote of the stock\n",
    "        get_historical_prices: retrieves historical close prices\n",
    "        get_stock_news: returns recent relevant company news\n",
    "    Parameters\n",
    "    ----------\n",
    "    ticker : str\n",
    "        exchange ticker of public traded company\n",
    "    Attributes\n",
    "    ----------\n",
    "        ticker : str\n",
    "            market ticker\n",
    "        valid : bool\n",
    "            ticker is a valid ticker\n",
    "        name : str\n",
    "            long company name\n",
    "        description : str\n",
    "            Brief description of company\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ticker):\n",
    "\n",
    "        self.ticker = ticker\n",
    "        self.valid = self._validate_ticker()\n",
    "        self.name, self.description = self._get_desc_details()\n",
    "\n",
    "    def get_quote(self):\n",
    "\n",
    "        \"\"\"Retrieves most recent stock price\"\"\"\n",
    "\n",
    "        quote_url = (\"http://finance.google.com/finance/info?client=ig\"\n",
    "                     + \"&q={}\"\n",
    "                    ).format(self.ticker)\n",
    "\n",
    "        if self.valid:\n",
    "            with request.urlopen(quote_url) as quote_response:\n",
    "                resp = quote_response.read()\n",
    "                quotes = resp.decode('ascii', 'ignore').replace('\\n', '')[3:]\n",
    "                return self._replace_keys(json.loads(quotes))\n",
    "\n",
    "\n",
    "    def get_historical_prices(self, start_date, end_date):\n",
    "\n",
    "        \"\"\"Class retrives historical stock prices between the two dates provided\n",
    "        Parameters\n",
    "        ------------\n",
    "        start_date : str\n",
    "            Older historical date to retrieve prices, '2017-06-30'\n",
    "        end_date : str\n",
    "            More recent historical date to retrive prices, '2017-07-31'\n",
    "        \"\"\"\n",
    "\n",
    "        if self.valid is True:\n",
    "            historic_url = (\"https://finance.google.com/finance/historical?\"\n",
    "                            + \"&q={0}\"\n",
    "                            + \"&startdate={1}\"\n",
    "                            + \"&enddate={2}\"\n",
    "                            + \"&output=csv\"\n",
    "                           ).format(self.ticker, start_date, end_date)\n",
    "            response_data = []\n",
    "            try:\n",
    "                with request.urlopen(historic_url) as response:\n",
    "                    page = response.read().decode('utf-8-sig').splitlines()\n",
    "\n",
    "                headers = page[0].split(',')\n",
    "                response_data = self._parse_hist_data(page[1:], headers, ',')\n",
    "\n",
    "            except HTTPError:\n",
    "\n",
    "                more_data = True\n",
    "                start = 0\n",
    "                while more_data:\n",
    "                    historic_url = (\"https://finance.google.com/finance/historical?\"\n",
    "                                    + \"&q={0}\"\n",
    "                                    + \"&startdate={1}\"\n",
    "                                    + \"&enddate={2}\"\n",
    "                                    + \"&num=200\"\n",
    "                                    + \"&start={3}\"\n",
    "                                   ).format(self.ticker, start_date, end_date, start)\n",
    "                    with request.urlopen(historic_url) as response:\n",
    "                        page = response.read()\n",
    "\n",
    "                    soup = BeautifulSoup(page, 'html.parser')\n",
    "                    table = soup.find(\"table\", class_='gf-table historical_price')\n",
    "                    text = table.text.split('\\n\\n')\n",
    "                    headers = text[1].split('\\n')\n",
    "\n",
    "                    response_data = (response_data\n",
    "                                     + self._parse_hist_data(\n",
    "                                         text[2:],\n",
    "                                         headers,\n",
    "                                         '\\n',\n",
    "                                         date_format='%b %d, %Y',\n",
    "                                         ))\n",
    "\n",
    "                    if len(response_data) < 200:\n",
    "                        more_data = False\n",
    "                    elif len(response_data) % 200 != 0:\n",
    "                        more_data = False\n",
    "                    else:\n",
    "                        start = start + 200\n",
    "\n",
    "            return response_data\n",
    "\n",
    "    def get_stock_news(self):\n",
    "\n",
    "        \"\"\"function will scrape google news to pull relelvant news stories\"\"\"\n",
    "\n",
    "        if self.valid is False:\n",
    "            return \"Invalid Stock\"\n",
    "\n",
    "        url = (\"https://finance.google.com/finance/company_news?\"\n",
    "               + \"q={0}\"\n",
    "               + \"&start=0\"\n",
    "               + \"&num=20\"\n",
    "              ).format(self.ticker)\n",
    "        with request.urlopen(url) as response:\n",
    "            res = response.read()\n",
    "\n",
    "        soup = BeautifulSoup(res, 'html.parser')\n",
    "        scraped_articles = []\n",
    "        articles = soup.find(id='news-main')\n",
    "\n",
    "        for article in articles.find_all(class_='g-section news sfe-break-bottom-16'):\n",
    "            header = article.find(class_='name')\n",
    "            details = header.select('a')\n",
    "            headline = details[0].getText()\n",
    "            url = details[0]['href']\n",
    "\n",
    "            byline = article.find(class_='byline')\n",
    "            src = byline.find(class_='src').getText()\n",
    "            article_date = byline.find(class_='date').getText()\n",
    "\n",
    "            scraped_articles.append(\n",
    "                {\n",
    "                    'headline': headline,\n",
    "                    'url': url,\n",
    "                    'src': src,\n",
    "                    'date': article_date\n",
    "                }\n",
    "            )\n",
    "        return scraped_articles\n",
    "\n",
    "    def _get_desc_details(self):\n",
    "        desc_url = 'https://finance.google.com/finance?q='\n",
    "        try:\n",
    "            with request.urlopen(desc_url + self.ticker) as response:\n",
    "                soup = BeautifulSoup(response.read(), 'html.parser')\n",
    "\n",
    "            try:\n",
    "                title = soup.title.text\n",
    "                company_name = title[:title.find(':')]\n",
    "            except AttributeError:\n",
    "                company_name = 'Company Name Unavailable'\n",
    "\n",
    "            try:\n",
    "                description = soup.find('div', class_='companySummary').text\n",
    "            except AttributeError:\n",
    "                description = 'Description Unavailable'\n",
    "        except HTTPError as error:\n",
    "            self.valid = False\n",
    "            print(error.reason)\n",
    "            return ('Unavailable', 'Unavailable')\n",
    "\n",
    "        return (company_name, description)\n",
    "\n",
    "    def _validate_ticker(self):\n",
    "        url = 'https://finance.google.com/finance?'\n",
    "\n",
    "        try:\n",
    "            with request.urlopen(url + '&q=' + self.ticker) as _:\n",
    "                return True\n",
    "        except HTTPError as _:\n",
    "            return False\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_hist_data(data, headers, delimiter, date_format='%d-%b-%y'):\n",
    "\n",
    "        parsed_data = []\n",
    "        for row in data:\n",
    "            cell = row.split(delimiter)\n",
    "            row_contents = {}\n",
    "            row_contents[headers[0]] = datetime.strptime(cell[0], date_format)\n",
    "            row_contents[headers[1]] = cell[1].replace(',', '')\n",
    "            row_contents[headers[2]] = cell[2].replace(',', '')\n",
    "            row_contents[headers[3]] = cell[3].replace(',', '')\n",
    "            row_contents[headers[4]] = cell[4].replace(',', '')\n",
    "            row_contents[headers[5]] = cell[5].replace(',', '')\n",
    "            parsed_data.append(row_contents)\n",
    "\n",
    "        return parsed_data\n",
    "\n",
    "    @staticmethod\n",
    "    def _replace_keys(quote):\n",
    "        updated_quote = {}\n",
    "        for key in quote[0]:\n",
    "            if key in DESCRIPTIVE_KEYS:\n",
    "                updated_quote[DESCRIPTIVE_KEYS[key]] = quote[0][key]\n",
    "        return updated_quote"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda7ea36a657f094256bb953582a44f81c5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
